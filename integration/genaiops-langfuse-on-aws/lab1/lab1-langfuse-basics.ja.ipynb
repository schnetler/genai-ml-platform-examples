{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Langfuse トレーシング\n",
    "\n",
    "このラボでは、Langfuse トレーシングを使用して LLM アプリケーションの実行をログに記録し分析する方法を学びます。Langfuse は AWS でのセルフホストをサポートしており、[クラウドバージョン](https://cloud.langfuse.com/)も利用可能です。Langfuse の [トレーシング](https://langfuse.com/docs/tracing)は、LLM アプリケーションの実行をログに記録し分析する方法であり、以下のリファレンスでは使用されるデータモデルの詳細な概要が提供されています。これは OpenTelemetry にインスパイアされています。\n",
    "\n",
    "## [トレースとオブザベーション](https://langfuse.com/docs/tracing-data-model)\n",
    "\n",
    "トレースは通常、単一のリクエストまたは操作を表します。それには、関数の全体的な入出力、およびユーザー、セッション、タグなどのリクエストに関するメタデータが含まれます。通常、トレースはアプリケーションの単一の API 呼び出しに対応します。\n",
    "\n",
    "各トレースには、実行の個々のステップをログに記録するための複数のオブザベーションが含まれます。\n",
    "\n",
    "- オブザベーションには異なるタイプがあります：\n",
    "    - イベントは基本的な構成要素です。トレース内の個別のイベントを追跡するために使用されます。\n",
    "    - スパンは、トレース内の作業単位の期間を表します。\n",
    "    - ジェネレーションは、AI モデルの生成をログに記録するために使用されるスパンのことです。モデル、プロンプト、および完了に関する追加属性が含まれます。ジェネレーションの場合、[トークンの使用とコスト](https://langfuse.com/docs/model-usage-and-cost)が自動的に計算されます。\n",
    "- オブザベーションはネスト可能です。\n",
    "\n",
    "![Trace and Observations](./images/trace-observation.png)\n",
    "![Trace and Observations UI](./images/trace-observation-ui.png)\n",
    "\n",
    "## [セッション](https://langfuse.com/docs/tracing-data-model)\n",
    "オプションで、トレースをセッションにグループ化できます。セッションは、同じユーザーインタラクションの一部であるトレースをグループ化するために使用されます。一般的な例として、チャットインターフェースのスレッドが挙げられます。トレースにセッションを追加するには、[セッションドキュメント](https://langfuse.com/docs/sessions)を参照してください。\n",
    "\n",
    "![Trace and Sessions](./images/trace-sessions.png)\n",
    "![Trace and Sessions UI](./images/trace-sessions-ui.png)\n",
    "\n",
    "\n",
    "## [スコア](https://langfuse.com/docs/tracing-data-model)\n",
    "\n",
    "トレースとオブザベーションは、[スコア](https://langfuse.com/docs/scores/overview)を使用して評価できます。スコアは評価メトリクスを保存する柔軟なオブジェクトであり、次のようになります：\n",
    "\n",
    "- 数値、カテゴリー、またはブール値\n",
    "- トレースに関連付けられる (必須)\n",
    "- 特定のオブザベーションにリンクされる (オプション)\n",
    "- 追加のコンテキストのためのコメントで注釈付けされる\n",
    "- スコア設定スキーマに対して検証される (オプション)\n",
    "\n",
    "![Trace and Scores](./images/trace-scores.png)\n",
    "\n",
    "開始するには、[スコアドキュメント](https://langfuse.com/docs/scores/overview)を参照してください。スコアタイプと属性の詳細については、[スコアデータモデルドキュメント](https://langfuse.com/docs/scores/data-model)を参照してください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前提条件\n",
    "\n",
    "> カーネルを選択していない場合は、右上隅にある「Select Kernel」ボタンをクリックし、Python Environmentsを選択して「.venv (Python 3.9.20) .venv/bin/python Recommended」を選択してください。\n",
    "\n",
    "> 各ノートブックセルを実行するには、Shift + Enterを押してください。\n",
    "\n",
    "> ℹ️ AWS が提供する一時アカウントを使用してインストラクター主導のワークショップに参加している場合は、これらの前提条件ステップを**スキップ**できます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依存関係と環境変数\n",
    "\n",
    "langfuse と boto3 を使用します：\n",
    "- Langfuse Python SDK とセルフホスティングデプロイメントを使用して、モデル呼び出しのトレーシング、プロンプト/モデル設定の管理、評価の実行により LLM アプリケーションをデバッグおよび改善します。\n",
    "- boto3 SDK を使用して、Amazon Bedrock または Amazon SageMaker 上のモデルと対話します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要な Python SDK をインストールするために以下のコマンドを実行してください。\n",
    "> AWS が主催するイベントで提供された AWS アカウントを使用している場合は、インストールをスキップしてください\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS ワークショップ環境を使用していない場合は、以下の行のコメントを外して依存関係をインストールしてください\n",
    "# %pip install -q langfuse boto3  --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".env ファイルで Langfuse プロジェクトと API キーをセットアップし、セルフホストまたはクラウドの Langfuse 環境に接続するための前提条件が完了していることを確認してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# すでに VS Code サーバーの .env で環境変数を定義している場合は、以下のセルはスキップしてください。\n",
    "# langfuse 用の環境変数を定義してください。\n",
    "# これらの値は Langfuse で API キーを作成する際に確認することができます。\n",
    "# import os\n",
    "# os.environ[\"LANGFUSE_SECRET_KEY\"] = \"xxxx\" # Langfuse プロジェクトのシークレットキー\n",
    "# os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"xxxx\" # Langfuse プロジェクトのパブリックキー\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"xxx\" # Langfuse ドメイン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "詳細については [Langfuse ドキュメント](https://langfuse.com/docs/get-started) を確認してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初期化と認証チェック\n",
    "以下のセルを実行して、共通ライブラリとクライアントを初期化してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary packages\n",
    "import sys\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import boto3\n",
    "from langfuse import Langfuse\n",
    "from langfuse.decorators import langfuse_context, observe\n",
    "from langfuse.model import PromptClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Bedrock クライアントと Amazon Bedrock ランタイム クライアントを作成します。このラボではリージョンが us-west-2 であることを確認してください。期待される結果は次の出力が表示されることです：\n",
    "\n",
    "```\n",
    "Found Nova model: US Nova Pro - us.amazon.nova-pro-v1:0\n",
    "Found Nova model: US Nova Lite - us.amazon.nova-lite-v1:0\n",
    "Found Nova model: US Nova Micro - us.amazon.nova-micro-v1:0\n",
    "```\n",
    "\n",
    "> us-west-2 の Nova モデルはクロスリージョン推論 (CRIS) でのみ呼び出すことができるため、model_id には \"us.\" プレフィックスが付いています。これは CRIS 呼び出しであることを示しています。これにより、モデル呼び出しに遅延が加わる可能性があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Amazon Bedrock のコンフィグへのアクセスに利用\n",
    "# このラボではリージョンを us-west-2 に設定\n",
    "bedrock = boto3.client(service_name=\"bedrock\", region_name=\"us-west-2\")\n",
    "\n",
    "# Amazon Nova モデルがこのリージョンで使えるかチェック\n",
    "models = bedrock.list_inference_profiles()\n",
    "nova_found = False\n",
    "for model in models[\"inferenceProfileSummaries\"]:\n",
    "    if (\n",
    "        \"Nova Pro\" in model[\"inferenceProfileName\"]\n",
    "        or \"Nova Lite\" in model[\"inferenceProfileName\"]\n",
    "        or \"Nova Micro\" in model[\"inferenceProfileName\"]\n",
    "    ):\n",
    "        print(\n",
    "            f\"Found Nova model: {model['inferenceProfileName']} - {model['inferenceProfileId']}\"\n",
    "        )\n",
    "        nova_found = True\n",
    "if not nova_found:\n",
    "    raise ValueError(\n",
    "        \"No Nova models found in available models. Please ensure you have access to Nova models.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langfuse クライアントを初期化し、認証情報が有効であることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "# langfuse クライアント\n",
    "langfuse = Langfuse()\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse has been set up correctly\")\n",
    "    print(f\"You can access your Langfuse instance at: {os.environ['LANGFUSE_HOST']}\")\n",
    "else:\n",
    "    print(\n",
    "        \"Credentials not found or invalid. Check your Langfuse API key and host in the .env file.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Bedrock Converse API の Langfuse ラッパー\n",
    "Amazon Bedrock Converse API を使用して、Amazon Bedrock モデルとの間でメッセージを送受信する対話型アプリケーションを作成できます。例えば、複数回のやり取りにわたって会話を維持し、役立つテクニカルサポートアシスタントなど、独自のニーズに合わせてパーソナリティやトーンをカスタマイズしたチャットボットを作成できます。\n",
    "\n",
    "Converse API を使用するには、Converse または ConverseStream（ストリーミング応答用）操作を使用してモデルにメッセージを送信します。既存の基本推論操作（InvokeModel または InvokeModelWithResponseStream）を会話アプリケーションに使用することも可能です。ただし、Converse API の使用を推奨します。これは、メッセージをサポートするすべての Amazon Bedrock モデルで動作する一貫した API を提供するためです。つまり、一度コードを書いて異なるモデルで使用できます。モデルに固有の推論パラメータがある場合、Converse API ではモデル固有の構造でそれらの固有パラメータを渡すこともできます。\n",
    "\n",
    "詳細については、[Converse API 操作で会話を実行する](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))  # 親ディレクトリをパスに追加\n",
    "from config import GUARDRAIL_CONFIG, MODEL_CONFIG\n",
    "from utils import converse, converse_tool_use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### チャットの例\n",
    "\n",
    "#### Converse API ラッパーを呼び出すためのヘルパー関数を定義する\n",
    "\n",
    "> ワークショップスタジオの紹介セクションにある [Langfuse セットアップ](https://catalog.workshops.aws/genaiops-langfuse/ja-JP/00-introduction/langfuse-setup) で言及されている Nova カスタムモデルの価格設定を設定したことを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@observe(name=\"Simple Chat\")\n",
    "def simple_chat(\n",
    "    model_config: dict,\n",
    "    messages: list,\n",
    "    prompt: PromptClient = None,\n",
    "    use_guardrails: bool = False,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    指定されたモデル設定を使ってシンプルなチャットインタラクションを実行する。\n",
    "\n",
    "    Args:\n",
    "        model_config (dict): チャットモデルの設定パラメータ\n",
    "        messages (list): 処理されるメッセージ辞書のリスト\n",
    "        prompt (PromptClient, optional): オプションのプロンプトクライアントで高度な処理が可能\n",
    "        use_guardrails (bool, optional): True の場合、追加のガードレール構成を適用\n",
    "\n",
    "    Returns:\n",
    "        dict: converse' 関数呼び出しからの応答\n",
    "    \"\"\"\n",
    "    config = model_config.copy()\n",
    "    if use_guardrails:\n",
    "        config[\"guardrailConfig\"] = GUARDRAIL_CONFIG\n",
    "    return converse(messages=messages, prompt=prompt, **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Case 1\n",
    "let's start with a single turn chat use case and use Nova Pro as the default model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorator to observe and track this function execution in Langfuse\n",
    "@observe(name=\"Single Turn Example\")\n",
    "def chat_single_model(\n",
    "    messages: list, model_type: str = \"nova_pro\", use_guardrails: bool = False\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    指定されたひとつの Amazon Nova モデルを使って、1 ターンのチャットインタラクションを実行\n",
    "\n",
    "    Args:\n",
    "        messages (list): ユーザーの入力クエリ\n",
    "        model_type (str): 利用する Nova モデル (nova_pro, nova_lite, or nova_micro)\n",
    "        use_guardrails (bool): モデル呼び出しにガードレールを適用するか\n",
    "\n",
    "    Returns:\n",
    "        dict: モデルからのレスポンスとステータスコード\n",
    "    \"\"\"\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=\"nova-user-1\",\n",
    "        tags=[\"lab1\", \"single-turn\"],\n",
    "    )\n",
    "\n",
    "    response = simple_chat(\n",
    "        model_config=MODEL_CONFIG[model_type],\n",
    "        messages=messages,\n",
    "        use_guardrails=use_guardrails,\n",
    "    )\n",
    "\n",
    "    return {\"model\": model_type, \"response\": response, \"statusCode\": 200}\n",
    "\n",
    "\n",
    "# チャット API をテストするためにサンプルリクエストを作成する\n",
    "# 高級リゾートのチェックインプロセスについて質問する\n",
    "print(\n",
    "    chat_single_model(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"高級リゾートでゲストをチェックインするプロセスを、ステップバイステップで説明して。\",\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# 自動の flush を待つのではなく、\n",
    "# Langfuse へのトレースデータの送信を強制する\n",
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Langfuse のダッシュボードで、トレース、モデルのコスト、モデルの使用状況の概要を確認できます:\\n{os.environ['LANGFUSE_HOST']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Langfuse Dashboard](./images/langfuse-dashboard-use-case-1.png)\n",
    "\n",
    "\n",
    "詳細なトレースは **Traces** セクションにあり、トレースをクリックすると詳細なトレースを表示できます。このトレースにはいくつかの重要な洞察があります。\n",
    "\n",
    "- 入力トークンは 12 で、出力トークンは 662 で、合計 675 トークンが使用されています\n",
    "\n",
    "- 使用されたモデルは us.amazon.nova-pro-v1:0 です\n",
    "\n",
    "- 温度、最大トークン数などのモデルパラメータが表示されます\n",
    "\n",
    "- 最も重要なのは、この呼び出しの総コストは $0.002129 です\n",
    "\n",
    "![Langfuse Dashboard](./images/langfuse-trace-use-case-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ユースケース 2\n",
    "このユースケースでは、1 つのセッション内で単一のトレースを実行し、比較のために異なる Nova モデルのバリアントを使用して 3 つの異なるオブザベーションを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@observe(name=\"Multi-Turn Example\")\n",
    "def chat_compare_models(\n",
    "    messages: list,\n",
    "    model_types: list = [\"nova_pro\", \"nova_lite\", \"nova_micro\"],\n",
    "    use_guardrails: bool = False,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    比較のために、すべての Amazon Nova モデルで同じクエリを実行\n",
    "\n",
    "    Args:\n",
    "        messages (list): ユーザーの入力クエリ\n",
    "        model_types (list): 利用する Nova モデル (nova_pro, nova_lite, or nova_micro)\n",
    "        use_guardrails (bool): モデル呼び出しにガードレールを適用するか\n",
    "    Returns:\n",
    "        dict: すべてのモデルからのレスポンスとステータスコード\n",
    "    \"\"\"\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=\"nova-user-1\",\n",
    "        session_id=\"model-comparison\",\n",
    "        tags=[\"lab1\", \"model-comparison\"],\n",
    "    )\n",
    "\n",
    "    responses = {}\n",
    "    for model_type in model_types:\n",
    "        responses[model_type] = simple_chat(\n",
    "            model_config=MODEL_CONFIG[model_type],\n",
    "            messages=messages,\n",
    "            use_guardrails=use_guardrails,\n",
    "        )\n",
    "\n",
    "    return {\"responses\": responses, \"statusCode\": 200}\n",
    "\n",
    "\n",
    "# ユーザーリクエスト\n",
    "print(\n",
    "    chat_compare_models(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"高級リゾートでゲストをチェックインするプロセスを、ステップバイステップで説明して。\",\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そのため、複数のオブザベーションを 1 つのトレースにまとめ、各オブザベーションのコストと使用量を確認することができます。Nova Micro はコストが最も低く、応答時間が最も速いことがわかります。\n",
    "\n",
    "![langfuse-traces-use-case-2](./images/langfuse-trace-use-case-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ユースケース 3\n",
    "今回は、`retrieve_context` と呼ばれるダミーの検索関数を使用して RAG ユースケースをシミュレートします。これは静的なコンテキストを返すダミー関数です。\n",
    "検索関数からのコンテキストをシステムプロンプトの一部として渡すことで、`simple_chat` 関数を再利用してモデルとチャットします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT = \"\"\"2025年1月1日\n",
    "シドニー: 24 度\n",
    "ニューヨーク: 13 度\n",
    "東京: 11 度\"\"\"\n",
    "\n",
    "\n",
    "@observe(name=\"Dummy Retrieval\")\n",
    "def retrieve_context(query: str) -> str:\n",
    "    \"\"\"クエリに対して静的なコンテキストを取得\"\"\"\n",
    "    return CONTEXT\n",
    "\n",
    "\n",
    "@observe(name=\"RAG Example\")\n",
    "def rag_api(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    静的なコンテキストを利用して検索拡張生成 (RAG) クエリを実行\n",
    "\n",
    "    Args:\n",
    "        query (str): ユーザークエリ\n",
    "\n",
    "    Returns:\n",
    "        dict: モデルからのレスポンスとステータスコード\n",
    "    \"\"\"\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=\"nova-user-1\",\n",
    "        session_id=\"rag-session\",\n",
    "        tags=[\"lab1\", \"rag-example\"],\n",
    "    )\n",
    "\n",
    "    context = retrieve_context(query)\n",
    "    messages = [\n",
    "        {\n",
    "            \"content\": f\"Context: {context}\\n上記のコンテキストに基づいて以下の質問に回答してください:\",\n",
    "            \"role\": \"system\",\n",
    "        },\n",
    "        {\"content\": query, \"role\": \"user\"},\n",
    "    ]\n",
    "    response = simple_chat(model_config=MODEL_CONFIG[\"nova_pro\"], messages=messages)\n",
    "\n",
    "    return {\"response\": response, \"statusCode\": 200}\n",
    "\n",
    "\n",
    "# ユーザーリクエスト\n",
    "print(rag_api(\"シドニーの天気はいかがですか？何かコメントはありますか？\"))\n",
    "\n",
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トレースを見ると、検索関数が呼び出され、コンテキストがシステムプロンプトの一部としてモデルに渡されるのがわかります。細かいモデルの呼び出しログを見ると、システムプロンプトとユーザープロンプトの両方を受け取り、レスポンスを返していることがわかります。\n",
    "\n",
    "![langfuse-traces-use-case-3](./images/langfuse-trace-use-case-3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ユースケース 4\n",
    "\n",
    "画像サポートによるマルチモーダル機能\n",
    "\n",
    "現代の AI システムは、テキスト、画像、音声など、さまざまな種類のデータ入力を処理し理解できるマルチモーダル機能を採用することが増えています。この例では、Langfuse が画像ベースの入力のトレーシングをサポートする方法を示します。これは特に以下に役立ちます：\n",
    "\n",
    "1. **画像分析**：視覚的なコンテンツの解釈と説明\n",
    "2. **視覚的質問応答**：画像のコンテキストに基づく質問への回答\n",
    "3. **ドキュメント処理**：スキャンされたドキュメントや画像から情報の抽出\n",
    "4. **コンテンツモデレーション**：不適切またはセンシティブな視覚的コンテンツの識別\n",
    "\n",
    "実装では、画像の URL がユーザープロンプトの一部として渡される構造化メッセージ形式を使用し、モデルがテキストクエリと視覚情報の両方を同時に処理できるようにします。この機能は、以下のようなアプリケーションで特に有用です：\n",
    "\n",
    "- E コマース製品認識\n",
    "- 医療画像分析\n",
    "- ソーシャルメディアコンテンツの理解\n",
    "\n",
    "Langfuse のトレーシング機能はこれらのマルチモーダルインタラクションにまで及び、モデルが画像入力をどのように処理し応答するかの可視性を提供します。これは、これらの複雑なシステムのデバッグと改善に不可欠です。\n",
    "\n",
    "このユースケースでは、画像をユーザープロンプトの一部として渡し、モデルがテキストと画像の両方を処理し、langfuse がプロセス全体をトレースします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@observe(name=\"Multi-Modal Image Example\")\n",
    "def vision_api(\n",
    "    query: str,\n",
    "    image_url: str,\n",
    ") -> Optional[str]:\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=\"nova-user-1\",\n",
    "        session_id=\"vision-session\",\n",
    "        tags=[\"lab1\", \"vision-example\"],\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"あなたは、画像を解釈して説明するように訓練された AI です。\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": query},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"response\": simple_chat(\n",
    "            model_config=MODEL_CONFIG[\"nova_pro\"], messages=messages\n",
    "        ),\n",
    "        \"statusCode\": 200,\n",
    "    }\n",
    "\n",
    "\n",
    "# image source: https://www.aboutamazon.com/news/aws/aws-reinvent-2024-keynote-live-news-updates\n",
    "print(\n",
    "    vision_api(\n",
    "        query=\"この画像では何が起こっていますか？\",\n",
    "        image_url=\"https://amazon-blogs-brightspot.s3.amazonaws.com/df/82/368cb270402e9739f04905ea9b19/swami-bedrock.jpeg\",\n",
    "    )\n",
    ")\n",
    "\n",
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langfuse は画像入力に対するトレースもサポートしており、モデルが画像を入力とするマルチモーダルなユースケースに非常に便利です。\n",
    "\n",
    "![langfuse-traces-use-case-4](./images/langfuse-trace-use-case-4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langfuse トレーシングを使用した Tool Use\n",
    "Tool Use により、AI モデルは外部関数や API と対話し、純粋なテキスト生成を超えて機能を拡張できます。これは特に以下に役立ちます：\n",
    "- リアルタイムデータへのアクセス（例：天気、株価）\n",
    "- 複雑な計算の実行\n",
    "- 外部システムとの統合\n",
    "- 非構造化ソース（例：テキスト、画像）から構造化データの抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ユースケース 1\n",
    "\n",
    "以下の例は、天気情報ツールの実装を示しています。ユーザーが天気について質問すると、モデルは：\n",
    "\n",
    "1. 天気データの必要性を認識します\n",
    "2. 構造化されたツール定義を通じて場所/単位パラメータを抽出します\n",
    "3. `get_current_weather` ツールを使用してフォーマットされた応答を返します\n",
    "\n",
    "期待される結果：モデルはサンフランシスコを場所として、摂氏を好みの単位として識別し、構造化されたツール応答を返しながら、Langfuse で完全なトレースの可視性を維持します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@observe(name=\"Tool Use Example\")\n",
    "def tool_use_api(query: str) -> list:\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=\"nova-user-1\",\n",
    "        session_id=\"tool-use-session\",\n",
    "        tags=[\"lab1\", \"tool-use\"],\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": query}]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"与えられたロケーションの現在の天気を取得する\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"都市と州、例: San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"response\": converse_tool_use(\n",
    "            messages, tools, tool_choice=\"auto\", **MODEL_CONFIG[\"nova_pro\"]\n",
    "        ),\n",
    "        \"statusCode\": 200,\n",
    "    }\n",
    "\n",
    "\n",
    "print(tool_use_api(query=\"サンフランシスコの天気はどうですか？摂氏で答えてください。\"))\n",
    "\n",
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![langfuse-traces-tool-use](./images/langfuse-trace-tool-use.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ユースケース 2\n",
    "以下の例は、マルチモーダルドキュメント書き起こしツールの実装を示しています。ユーザーがドキュメントの転写を要求すると、モデルは：\n",
    "\n",
    "1. 請求書書き起こしのスキーマを認識します\n",
    "2. 構造化されたツール定義を通じて画像から構造化データを抽出します\n",
    "3. `dependentSchemas` を適用して、抽出に対する追加の分類と推論を提供します\n",
    "\n",
    "期待される結果：モデルは請求書からすべてのメタデータと明細項目を抽出し、各フィールドの分類と推論を含む JSON 形式の構造化データを出力する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "<instructions>\n",
    "  - JSON レスポンス内のクォートを必ずエスケープしてください\n",
    "  - フィールド値が欠損していたら \"\" を返してください\n",
    "  - すべての <document/> フィールドに dependentSchemas を適用してください\n",
    "</instructions>\n",
    "\n",
    "<document>\n",
    "{\n",
    "    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n",
    "    \"$id\": \"/schemas/document\",\n",
    "    \"type\": \"object\",\n",
    "    \"description\": \"A document with the fields to transcribe\",\n",
    "    \"properties\": {\n",
    "        \"doc_type\": { \"properties\":{\"value\":{\"type\":\"string\"}}, \"description\": \"Type of Document: Receipt\" },\n",
    "        \"receipt_number\": { \"properties\":{\"value\":{\"type\":\"string\"}}, \"description\": \"The receipt number or other identifier number\" },\n",
    "        \"doc_amount_total\": { \"properties\":{\"value\":{\"type\":\"number\"}}, \"description\": \"The total receipt amount\" },\n",
    "        \"currency\": { \"properties\":{\"value\":{\"type\":\"string\"}}, \"description\": \"AUD/USD/CAD\" },\n",
    "        \"vendor_business_number\": { \"properties\":{\"value\":{\"type\":\"string\"}}, \"description\": \"Vendor's business identification number e.g. ABN\" },\n",
    "        \"vendor_name\": { \"properties\":{\"value\":{\"type\":\"string\"}}, \"description\": \"Business name issueing the receipt\" },\n",
    "        \"vendor_address\": { \"properties\":{\"value\":{\"type\":\"string\"}}, \"description\": \"Vendor's site address\" },\n",
    "        \"vendor_phone\": { \"properties\":{\"value\":{\"type\":\"string\"}}, \"description\": \"Vendor's phone number\" },\n",
    "        \"payment_method\": { \"properties\":{\"value\":{\"type\":\"string\"}}, \"description\": \"The payment type, e.g. EFTPOS, Card\" },\n",
    "        \"date_issued\": { \"properties\":{\"value\":{\"format\": \"YYYY-MM-DDThh:mm:ss\"}}, \"description\": \"Date document was issued\"},\n",
    "        \"line_items_amount_total\": { \"properties\":{\"value\":{\"type\":\"number\"}}, \"description\": \"Calculated sum of line item's line_amount fields\" }\n",
    "    },\n",
    "    \"dependentSchemas\": {\n",
    "        \"value\": {\n",
    "            \"properties\": {\n",
    "                \"inference\": { \"type\": \"integer\", \"description\": \"0=EXPLICIT|1=DERIVED|2=MISSING|3=OTHER\" },\n",
    "                \"source\": { \"type\": \"string\", \"description\": \"Source locations in the document for explicit and derived fields\" }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "<document/>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@observe(name=\"Vision Tool Use Example\")\n",
    "def vision_tool_use_api(\n",
    "    query: str,\n",
    "    image_url: str,\n",
    ") -> list:\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=\"nova-user-1\",\n",
    "        session_id=\"tool-use-session\",\n",
    "        tags=[\"lab1\", \"tool-use\"],\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": query},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"transcribe_documents\",\n",
    "                \"description\": \"Extract all <document/> fields with the highest accuracy following <instructions/>\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"documents\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\"$ref\": \"/schemas/document\"},\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"documents\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"response\": converse_tool_use(\n",
    "            messages, tools, tool_choice=\"auto\", **MODEL_CONFIG[\"nova_pro\"]\n",
    "        ),\n",
    "        \"statusCode\": 200,\n",
    "    }\n",
    "\n",
    "\n",
    "# image source: https://aws.amazon.com/blogs/machine-learning/announcing-expanded-support-for-extracting-data-from-invoices-and-receipts-using-amazon-textract/\n",
    "print(\n",
    "    vision_tool_use_api(\n",
    "        query=\"この請求書を書き起こしてください。すべての <document/> フィールドに対して dependentSchemas を適用するよう注意してください。\",\n",
    "        image_url=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2021/07/22/ml3911-img17.jpg\",\n",
    "    )\n",
    ")\n",
    "\n",
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"./images/langfuse-trace-tool-use-vision.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## プロンプト管理\n",
    "### プロンプト管理とは何か？\n",
    "\n",
    "プロンプト管理は、LLM アプリケーションでプロンプトを保存、バージョン管理、および取得するための体系的なアプローチです。プロンプト管理の重要な側面には、バージョン管理、コードからプロンプトを分離、モニタリング、ロギング、プロンプトの最適化、およびアプリケーションやツールスタックの残りの部分とのプロンプトの統合が含まれます。\n",
    "\n",
    "Langfuse を使用して、プロンプトを効果的に**管理**および**バージョン管理**します。Langfuse のプロンプト管理は、プロンプト**CMS**（コンテンツ管理システム）です。\n",
    "\n",
    "### なぜプロンプト管理を使用するのですか？\n",
    "\n",
    "CMS を使用することの典型的な利点がここに適用されます：\n",
    "\n",
    "- 分離：アプリケーションを再デプロイせずに新しいプロンプトをデプロイできる。\n",
    "- 非技術的なユーザーが Langfuse コンソール経由でプロンプトを作成および更新できる。\n",
    "- プロンプトの以前のバージョンにすぐにロールバックできる。\n",
    "- 異なるプロンプトバージョンを並べて比較できる。\n",
    "\n",
    "プラットフォームの利点：\n",
    "\n",
    "- Langfuse Tracing でプロンプトバージョンのパフォーマンスを追跡できる。\n",
    "\n",
    "他の実装と比較したパフォーマンス上の利点：\n",
    "\n",
    "-  プロンプトの最初の使用後、クライアント側のキャッシュと非同期キャッシュ更新により、レイテンシーの影響はない。\n",
    "-  テキストおよびチャットプロンプトをサポートする。\n",
    "-  UI、SDK、または API を介して編集/管理できる。\n",
    "\n",
    "Langfuse でプロンプトを作成するには、いくつかの方法があります：\n",
    "\n",
    "-  Langfuse コンソール\n",
    "-  Langfuse SDK\n",
    "-  Langfuse API\n",
    "\n",
    "このワークショップでは、Langfuse Python 低レベル SDK を使用して、「モジュール 1 - Amazon Nova モデルを使ったプロンプトエンジニアリング」からのプロンプトの例を再利用してプロンプトを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langfuse クライアントの初期化\n",
    "langfuse = Langfuse()\n",
    "\n",
    "# COT を使わないチャットプロンプトの作成\n",
    "langfuse.create_prompt(\n",
    "    name=\"software-development-project-management-without-COT\",\n",
    "    type=\"chat\",\n",
    "    prompt=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"あなたは小さなソフトウェア開発チームのプロジェクトマネージャーです。あなたは開発プロセスを効率化し、タイムリーな納品を実現したいと考えています。\",\n",
    "        }\n",
    "    ],\n",
    "    labels=[\"dev\"],\n",
    "    config={\n",
    "        \"model\": MODEL_CONFIG[\"nova_pro\"][\"model_id\"],\n",
    "        \"maxTokens\": MODEL_CONFIG[\"nova_pro\"][\"inferenceConfig\"][\"maxTokens\"],\n",
    "        \"temperature\": MODEL_CONFIG[\"nova_pro\"][\"inferenceConfig\"][\"temperature\"],\n",
    "    },  # 開発と実験フェーズ用\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COT を使ったチャットプロンプトの作成\n",
    "langfuse.create_prompt(\n",
    "    name=\"software-development-project-management-with-COT\",\n",
    "    type=\"chat\",\n",
    "    prompt=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"あなたは小さなソフトウェア開発チームのプロジェクトマネージャーです。あなたは開発プロセスを効率化し、タイムリーな納品を実現したいと考えています。以下の手順に従ってください:\\n\n",
    "{{step1}}\\n\n",
    "\\n\n",
    "{{step2}}\\n\n",
    "\\n\n",
    "{{step3}}\\n\n",
    "\\n\n",
    "{{step4}}\\n\"\"\",\n",
    "        }\n",
    "    ],\n",
    "    labels=[\"dev\"],\n",
    "    config={\n",
    "        \"model\": MODEL_CONFIG[\"nova_pro\"][\"model_id\"],\n",
    "        \"maxTokens\": MODEL_CONFIG[\"nova_pro\"][\"inferenceConfig\"][\"maxTokens\"],\n",
    "        \"temperature\": MODEL_CONFIG[\"nova_pro\"][\"inferenceConfig\"][\"temperature\"],\n",
    "    },  # 開発と実験フェーズ用\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 つの langfuse プロンプトが正常に作成されているのがわかります。\n",
    "\n",
    "![langfuse-traces-prompt-management](./images/langfuse-prompt-management.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 両方のプロンプトを取得し、変数に値を入力してプロンプトを呼び出す\n",
    "langfuse = Langfuse()\n",
    "\n",
    "# プロンプトの最新バージョンを取得\n",
    "sdpm_with_cot_prompt = langfuse.get_prompt(\n",
    "    \"software-development-project-management-with-COT\", type=\"chat\", label=\"dev\"\n",
    ")\n",
    "# プロンプトテンプレートに変数を挿入\n",
    "sdpm_with_cot_prompt_compiled = sdpm_with_cot_prompt.compile(\n",
    "    step1=\"要件を定義する\",\n",
    "    step2=\"タスクに分解する\",\n",
    "    step3=\"期限を設定する\",\n",
    "    step4=\"進捗を監視し、最適化する\",\n",
    ")\n",
    "\n",
    "sdpm_without_cot_prompt = langfuse.get_prompt(\n",
    "    \"software-development-project-management-without-COT\", type=\"chat\", label=\"dev\"\n",
    ")\n",
    "sdpm_without_cot_prompt_compiled = sdpm_without_cot_prompt.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdpm_with_cot_prompt_compiled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDK の呼び出しにプロンプトオブジェクトを追加することで、Langfuse Tracing の生成とプロンプトバージョンをリンクできるようになりました。この連携により、プロンプトのバージョンと名前によるメトリクスの追跡が可能になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 管理しているプロンプトを用いた会話\n",
    "@observe()\n",
    "def main():\n",
    "    langfuse_context.update_current_trace(\n",
    "        name=\"prompt-management-trace\",\n",
    "        user_id=\"nova-user-1\",\n",
    "        session_id=\"link-prompt-session\",\n",
    "        tags=[\"lab1\"],\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": sdpm_with_cot_prompt_compiled[0][\"role\"],\n",
    "            \"content\": sdpm_with_cot_prompt_compiled[0][\"content\"],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    simple_chat(\n",
    "        model_config=MODEL_CONFIG[\"nova_pro\"],\n",
    "        messages=messages,\n",
    "        prompt=sdpm_with_cot_prompt,\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": sdpm_without_cot_prompt_compiled[0][\"role\"],\n",
    "            \"content\": sdpm_without_cot_prompt_compiled[0][\"content\"],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    simple_chat(\n",
    "        model_config=MODEL_CONFIG[\"nova_pro\"],\n",
    "        messages=messages,\n",
    "        prompt=sdpm_without_cot_prompt,\n",
    "    )\n",
    "\n",
    "\n",
    "main()\n",
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トレースがプロンプトのバージョンとプロンプト名にリンクしていることがわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![langfuse-traces-prompt-management](./images/langfuse-link-prompt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab1 まとめ：\n",
    "Lab1 では、Langfuse と AWS を統合してプロンプトトレースを効果的に管理するための基本を探求しました。\n",
    "トレースの更新方法、プロンプトをユーザーセッションにリンクする方法、そしてこれらのリンクを実際の例で視覚化する方法を示しました。\n",
    "\n",
    "このラボを締めくくるにあたり、獲得した基礎スキルについて少し考えてみてください。\n",
    "今、AWS のイベントに参加している場合は、次のラボに進む前に、ワークショップスタジオに戻って追加の指示を確認してください。次のラボでは、RAG 関連のトレーシングと評価についてさらに深く掘り下げます。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
