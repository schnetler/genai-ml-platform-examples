{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ragas ã¨ Langfuse ã‚’ä½¿ç”¨ã—ãŸ Retrieval-Augmented Generation (RAG) ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®è©•ä¾¡\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€[RAGAS](https://docs.ragas.io/en/v0.1.21/index.html) ãªã©ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ Retrieval-Augmented Generation (RAG) ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å“è³ªã‚’è©•ä¾¡ã™ã‚‹æ–¹æ³•ã‚’æ¢æ±‚ã—ã€[Langfuse](https://langfuse.com/) ã®æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ã¦ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã¨ã‚¹ãƒ‘ãƒ³ã§ RAG ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç®¡ç†ãŠã‚ˆã³ãƒˆãƒ¬ãƒ¼ã‚¹ã—ã¾ã™ã€‚Amazon Bedrock ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã¨ RAG ãƒãƒƒãƒç”Ÿæˆçµæœã‚’ä½œæˆã—ã¦ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³è©•ä¾¡ã¨ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚’ç¤ºã—ã¾ã™ã€‚\n",
    "\n",
    "> â„¹ï¸ æ³¨æ„ï¼šã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ä¸€éƒ¨ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šãŒå¿…è¦ã§ã™ã€‚\n",
    ">\n",
    "> ã‚»ãƒ«ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šãŒå¿…è¦ãªå ´åˆã€ğŸ‘‰ çµµæ–‡å­—ä»˜ãã®ã“ã®ã‚³ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã®ã‚ˆã†ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚\n",
    ">\n",
    "> ğŸ‘‰ çµµæ–‡å­—ä»˜ãã®æŒ‡ç¤ºã«æ³¨æ„ã‚’æ‰•ã„ã€ã‚³ãƒ¼ãƒ‰ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹å‰ã« AWS ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã¾ãŸã¯å¯¾å¿œã™ã‚‹ã‚»ãƒ«ã§è¨­å®šã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å‰ææ¡ä»¶\n",
    "\n",
    "> ã‚«ãƒ¼ãƒãƒ«ã‚’é¸æŠã—ã¦ã„ãªã„å ´åˆã¯ã€å³ä¸Šéš…ã«ã‚ã‚‹ã€ŒSelect Kernelã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã€Python Environmentsã‚’é¸æŠã—ã¦ã€Œ.venv (Python 3.9.20) .venv/bin/python Recommendedã€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "> å„ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€Shift + Enterã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "> â„¹ï¸ AWS ãŒæä¾›ã™ã‚‹ä¸€æ™‚ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ãƒ¼ä¸»å°ã®ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ã«å‚åŠ ã—ã¦ã„ã‚‹å ´åˆã¯ã€ã“ã‚Œã‚‰ã®å‰ææ¡ä»¶ã‚¹ãƒ†ãƒƒãƒ—ã‚’**ã‚¹ã‚­ãƒƒãƒ—**ã§ãã¾ã™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon OpenSearch ã®è¿½åŠ æ¨©é™\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§æ‰‹å‹•ã® Amazon Bedrock Knowledge Bases ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †ã‚’å®Œäº†ã™ã‚‹ã«ã¯ã€**AWS Console ãƒ¦ãƒ¼ã‚¶ãƒ¼/ãƒ­ãƒ¼ãƒ«**ã«ä»¥ä¸‹ãŒå¿…è¦ã§ã™ï¼š\n",
    "\n",
    "- [Amazon OpenSearch ãƒ™ã‚¯ã‚¿ãƒ¼ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ“ä½œã™ã‚‹æ¨©é™](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/serverless-vector-search.html)\n",
    "- **IAM ãƒ­ãƒ¼ãƒ«ã®ä½œæˆ**ã¨ãƒãƒªã‚·ãƒ¼ã®æ·»ä»˜ã‚’å«ã‚€æ¨©é™ï¼š`iam:AttachRolePolicy`ã€`iam:CreateRole`ã€`iam:DetachRolePolicy`ã€`iam:GetRole`ã€`iam:PassRole`ã€`iam:CreatePolicy`ã€`iam:CreatePolicyVersion`ã€ãŠã‚ˆã³ `iam:DeletePolicyVersion`ã€‚\n",
    "\n",
    "> â„¹ï¸ **æ³¨æ„ï¼š** ãƒ†ã‚¹ãƒˆã§ã¯ã€ä¸Šè¨˜ã®ãƒªãƒ³ã‚¯ã•ã‚ŒãŸ `aoss` ãƒãƒªã‚·ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã®ã¿ã‚’ä½¿ç”¨ã—ã¦ Amazon Bedrock KB ã‚’ä½œæˆã—ã‚ˆã†ã¨ã—ãŸã¨ãã« `NetworkError` ã®å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã“ã‚Œã¯ä»£ã‚ã‚Šã« `*` ã«å¯¾ã—ã¦ `aoss:*` ã‚’ä»˜ä¸ã™ã‚‹ã“ã¨ã§è§£æ±ºã•ã‚Œã¾ã—ãŸãŒã€æœ¬ç•ªç’°å¢ƒã§ä½¿ç”¨ã™ã‚‹å‰ã«ã“ã‚Œã‚‰ã®æ¨©é™ã‚’æ¸›ã‚‰ã™ã“ã¨ã‚’æ¤œè¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "[AWS Console for Identity and Access Management (IAM)](https://console.aws.amazon.com/iam/home?#/home) ã‚’å‚ç…§ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¾ãŸã¯ãƒ­ãƒ¼ãƒ«ã«æ¨©é™ã‚’ä»˜ä¸ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¾å­˜é–¢ä¿‚ã¨ç’°å¢ƒå¤‰æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ç’°å¢ƒã‚’ä½¿ç”¨ã—ã¦ã„ãªã„å ´åˆã¯ã€ä»¥ä¸‹ã®è¡Œã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤–ã—ã¦ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„\n",
    "# %pip install langfuse datasets ragas python-dotenv langchain-aws boto3 --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".env ãƒ•ã‚¡ã‚¤ãƒ«ã§ Langfuse ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ API ã‚­ãƒ¼ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã€ã‚»ãƒ«ãƒ•ãƒ›ã‚¹ãƒˆã¾ãŸã¯ã‚¯ãƒ©ã‚¦ãƒ‰ã® Langfuse ç’°å¢ƒã«æ¥ç¶šã™ã‚‹ãŸã‚ã®å‰ææ¡ä»¶ãŒå®Œäº†ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã™ã§ã« VS Code ã‚µãƒ¼ãƒãƒ¼ã® .env ã§ç’°å¢ƒå¤‰æ•°ã‚’å®šç¾©ã—ã¦ã„ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚\n",
    "# langfuse ç”¨ã®ç’°å¢ƒå¤‰æ•°ã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚\n",
    "# ã“ã‚Œã‚‰ã®å€¤ã¯ Langfuse ã§ API ã‚­ãƒ¼ã‚’ä½œæˆã™ã‚‹éš›ã«ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "# import os\n",
    "# os.environ[\"LANGFUSE_SECRET_KEY\"] = \"xxxx\" # Langfuse ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚­ãƒ¼\n",
    "# os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"xxxx\" # Langfuse ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‘ãƒ–ãƒªãƒƒã‚¯ã‚­ãƒ¼\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"xxx\" # Langfuse ãƒ‰ãƒ¡ã‚¤ãƒ³"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è©³ç´°ã«ã¤ã„ã¦ã¯ [Langfuse ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://langfuse.com/docs/get-started) ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆæœŸåŒ–ã¨èªè¨¼ãƒã‚§ãƒƒã‚¯\n",
    "ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ã€å…±é€šãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Any, List, Optional\n",
    "\n",
    "# å¤–éƒ¨ã®ä¾å­˜é–¢ä¿‚:\n",
    "import pandas as pd  # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã®æ“ä½œç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Bedrock ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã€ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèªã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3  # AWS Python SDK å…¨èˆ¬ (Amazon Bedrock ã‚’å«ã‚€)\n",
    "\n",
    "# Amazon Bedrock ã®è¨­å®šã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã«ä½¿ç”¨\n",
    "bedrock = boto3.client(service_name=\"bedrock\", region_name=\"us-west-2\")\n",
    "\n",
    "bedrock_agent_runtime = boto3.client(\n",
    "    service_name=\"bedrock-agent-runtime\", region_name=\"us-west-2\"\n",
    ")\n",
    "\n",
    "# ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèª\n",
    "models = bedrock.list_inference_profiles()\n",
    "for model in models[\"inferenceProfileSummaries\"]:\n",
    "    print(model[\"inferenceProfileName\"] + \" - \" + model[\"inferenceProfileId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langfuse ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã€èªè¨¼æƒ…å ±ãŒæœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "# langfuse ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ\n",
    "langfuse = Langfuse()\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse ã¯æ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã¾ã™\")\n",
    "    print(f\"Langfuse ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¸ã¯ã“ã¡ã‚‰ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™: {os.environ['LANGFUSE_HOST']}\")\n",
    "else:\n",
    "    print(\n",
    "        \"èªè¨¼æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«å†…ã® Langfuse API ã‚­ãƒ¼ã¨ãƒ›ã‚¹ãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "æ¬¡ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦ retrieval-augmented generation (RAG) ã‚’å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ Amazon S3 ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ï¼ˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ï¼‰ã‚’ä½œæˆã—ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€ä»¥ä¸‹ã‚’è¨­å®šã—ã¾ã™ï¼š\n",
    "\n",
    "- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã® Amazon S3 `bucket_name`\n",
    "- ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãŒä¿å­˜ã•ã‚Œã‚‹ãƒã‚±ãƒƒãƒˆå†…ã®ãƒ•ã‚©ãƒ«ãƒ€ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "botosess = boto3.Session(region_name=\"us-west-2\")\n",
    "region = botosess.region_name\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "bucket_name = f\"eval-{account_id}-{region}\"\n",
    "s3_prefix = \"bedrock-rag-eval\"\n",
    "\n",
    "# S3 ãƒã‚±ãƒƒãƒˆãŒå­˜åœ¨ã™ã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã€å­˜åœ¨ã—ãªã„å ´åˆã¯ãƒã‚±ãƒƒãƒˆã‚’ä½œæˆ\n",
    "s3 = boto3.client(\"s3\")\n",
    "try:\n",
    "    s3.head_bucket(Bucket=bucket_name)\n",
    "    print(f\"Bucket {bucket_name} exists\")\n",
    "except ClientError:\n",
    "    print(f\"Creating bucket {bucket_name}\")\n",
    "    s3.create_bucket(\n",
    "        Bucket=bucket_name, CreateBucketConfiguration={\"LocationConstraint\": region}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon S3 ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹\n",
    "\n",
    "ã¾ãšã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ Amazon S3 ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã ã‘ã§å®Œäº†ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_s3uri = f\"s3://{bucket_name}/{s3_prefix}/corpus\"\n",
    "print(f\"Syncing corpus to:\\n{corpus_s3uri}/\")\n",
    "\n",
    "# ãƒ•ã‚©ãƒ«ãƒ€ã‚’ S3 ãƒã‚±ãƒƒãƒˆã«å†å¸°çš„ã«åŒæœŸã™ã‚‹ãŸã‚ã« AWS CLI ã‚’ä½¿ç”¨\n",
    "!aws s3 sync --quiet ./datasets/corpus {corpus_s3uri}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã™ã‚‹\n",
    "> ğŸ‘‰ ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ã¯ã€ã‚³ãƒ¼ãƒ‰ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã ã‘ã§ãªãã€æ‰‹å‹•ã§å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ†ã‚¹ãƒˆç”¨ã®å®Ÿéš›ã® Bedrock ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’è¨­å®šã™ã‚‹æœ€ã‚‚ç°¡å˜ãªæ–¹æ³•ã¯ã€**AWS ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚’é€šã˜ã¦æ‰‹å‹•ã§è¡Œã†**ã“ã¨ã§ã™ï¼š\n",
    "\n",
    "1. ã¾ãšã€[Amazon Bedrock ã® AWS ã‚³ãƒ³ã‚½ãƒ¼ãƒ«](https://console.aws.amazon.com/bedrock/home?#/knowledge-bases)ã‚’**é–‹ã**ã€å·¦å´ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ *Orchestration > Knowledge bases* ã‚’é¸æŠã—ã¾ã™ã€‚ä»¥ä¸‹ã«ç¤ºã™ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å‚ç…§ã—ã¦ãã ã•ã„ï¼š\n",
    "\n",
    "    > â„¹ï¸ UI ã®å³ä¸Šéš…ã«ã‚ã‚‹ *AWS Region* ãŒæ­£ã—ã„ (us-west-2 ã§ã‚ã‚‹) ã“ã¨ã‚’**ç¢ºèª**ã—ã¦ãã ã•ã„\n",
    "\n",
    "![KB Console](images/bedrock-kbs/01-bedrock-kb-console.png \"Amazon Bedrock ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã® AWS ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã€ã€ŒCreate knowledge baseã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Create knowledge base** ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã€**Knowledge Base with vector store** ã‚’é¸æŠã—ã¾ã™ã€‚é–‹ãç”»é¢ã§ï¼š\n",
    "\n",
    "- **knowledge base name** ã«ã¯ `example-squad-kb` ã¨å…¥åŠ›ã—ã¾ã™\n",
    "- **knowledge base description** ã«ã¯ã€`Demo knowledge base for question answering evaluation` ã®ã‚ˆã†ãªã‚‚ã®ã‚’å…¥åŠ›ã§ãã¾ã™\n",
    "- ãã®ä»–ã®è¨­å®šã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã¾ã¾ã«ã—ã¾ã™ï¼ˆæ–°ã—ã„å®Ÿè¡Œãƒ­ãƒ¼ãƒ«ã®ä½œæˆã‚’è¨±å¯ã—ã€ã‚¿ã‚°ãªã—ï¼‰\n",
    "- ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã¨ã—ã¦ Amazon S3 ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰\n",
    "\n",
    "è¨­å®šã¯ä»¥ä¸‹ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®ã‚ˆã†ã«ãªã‚‹ã¯ãšã§ã™ï¼š\n",
    "\n",
    "![KB Basics](images/bedrock-kbs/02a-create-kb-basics.png \"Bedrock ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ä½œæˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã‚¹ãƒ†ãƒƒãƒ— 1 ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆï¼šKB åã€èª¬æ˜ã€ï¼ˆæ–°è¦ä½œæˆï¼‰å®Ÿè¡Œãƒ­ãƒ¼ãƒ«ã€ï¼ˆç©ºã®ï¼‰ã‚¿ã‚°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ•ã‚©ãƒ¼ãƒ ã®æœ€å¾Œã«ã€ŒNextã€ãƒœã‚¿ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Next** ç”»é¢ã§ã€S3 ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "\n",
    "    ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ S3 ã®ã¾ã¾ã«ã—ã¦ã€å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ä½œæˆã—ãŸãƒã‚±ãƒƒãƒˆã¨ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é¸æŠã—ã€Amazon Bedrock ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "\n",
    "![](images/bedrock-kbs/02b-create-kb-data-source.png \"Cohere Embed Multilingual åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã¨ quick-create vector store ã‚’å«ã‚€ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­å®šã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã€‚ã€ŒNextã€ãƒœã‚¿ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Next** ç”»é¢ã§ã€ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨­å®šã—ã¾ã™ï¼š\n",
    "\n",
    "    *embeddings model* ã«ã¯ `Cohere Embed Multilingual` ã‚’é¸æŠã—ã¾ã™\n",
    "\n",
    "    > â„¹ï¸ [Amazon Bedrock ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã‚³ãƒ³ã‚½ãƒ¼ãƒ«](https://console.aws.amazon.com/bedrock/home?#/modelaccess) ã§ã€ç¾åœ¨ã®ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã§ã“ã®ãƒ¢ãƒ‡ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’æœ‰åŠ¹ã«ã—ã¦ã„ã‚‹ã“ã¨ã‚’**ç¢ºèª**ã—ã¦ãã ã•ã„ã€‚\n",
    "    >\n",
    "    > å¿…è¦ã«å¿œã˜ã¦ã€åˆ¥ã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "\n",
    "    *Vector database* ã«ã¯ `Quick create a new vector store` ã‚’é¸æŠã—ã¾ã™\n",
    "\n",
    "    ã“ã®ç”»é¢ã¾ãŸã¯ [Amazon Bedrock é–‹ç™ºè€…ã‚¬ã‚¤ãƒ‰](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-setup.html) ã§ã€Amazon Bedrock ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãŒã‚µãƒãƒ¼ãƒˆã™ã‚‹ã•ã¾ã–ã¾ãªãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã«é–¢ã™ã‚‹è©³ç´°æƒ…å ±ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã¯ã€æ–°ã—ã„ [Amazon OpenSearch Serverless](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/serverless-overview.html) ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãŒä½œæˆã•ã‚Œã¾ã™\n",
    "\n",
    "    ä»¥ä¸‹ã®ã‚ˆã†ã«ä»–ã®è¨­å®šã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã¾ã¾ã«ã—ã€æ¬¡ã«é€²ã‚“ã§ãã ã•ã„ï¼š\n",
    "\n",
    "![](images/bedrock-kbs/02c-create-kb-index.png \"Cohere Embed Multilingual åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã¨ quick-create vector store ã‚’å«ã‚€ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­å®šã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã€‚ã€ŒNextã€ãƒœã‚¿ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Next** ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è¨­å®šã‚’ç¢ºèªã—ã€æ¬¡ã« **Create knowledge base** ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Œäº†ã—ã¾ã™ã€‚\n",
    "\n",
    "    > â° ä½œæˆãŒå®Œäº†ã™ã‚‹ã¾ã§ã« **æ•°åˆ†**ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ä¸Šã«ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã™ã‚‹ã¨é€²è¡ŒçŠ¶æ³ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ãƒãƒŠãƒ¼ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã¯ãšã§ã™ã€‚ã¾ãŸã¯åˆ¥ã®ã‚¿ãƒ–ã§ã€[Amazon OpenSearch Serverless Collections ã‚³ãƒ³ã‚½ãƒ¼ãƒ«](https://console.aws.amazon.com/aos/home?#opensearch/collections) ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ã“ã“ã§ã¯ã€åŸºç›¤ã¨ãªã‚‹ãƒ™ã‚¯ã‚¿ãƒ¼ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "    ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã‚‹ã¨ã€ä»¥ä¸‹ã«ç¤ºã™ã‚ˆã†ã«è©³ç´°ç”»é¢ã«ç§»å‹•ã—ã¾ã™ï¼š\n",
    "\n",
    "![](images/bedrock-kbs/03-kb-detail-page.png \"ä½œæˆã•ã‚ŒãŸ Amazon Bedrock ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®è©³ç´°ç”»é¢ã€ä½œæˆæˆåŠŸãƒãƒŠãƒ¼ã‚’è¡¨ç¤ºã€‚'Knowledge base overview'ï¼ˆKB IDã€åå‰ã€ãã®ä»–ã®è©³ç´°ã‚’å«ã‚€ï¼‰ã€ã€ŒTagsã€ï¼ˆç©ºï¼‰ã€ã€ŒData sourceã€ï¼ˆ1 ã¤ã® Amazon S3 ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãŒãƒªã‚¹ãƒˆã•ã‚Œã¦ã„ã‚‹ï¼‰ã€ã€ŒEmbeddings modelã€ï¼ˆCohere Embedï¼‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå«ã¾ã‚Œã€å³å´ã«ã¯å¯¾è©±å‹ã®ã€ŒTest knowledge baseã€ãƒãƒ£ãƒƒãƒˆã‚µã‚¤ãƒ‰ãƒãƒ¼ãŒã‚ã‚Šã€ä¸€éƒ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãŒåŒæœŸã•ã‚Œã¦ã„ãªã„ã¨ã„ã†è­¦å‘ŠãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. å…ˆã»ã©ã®è­¦å‘Šãƒœãƒƒã‚¯ã‚¹ã§è¿°ã¹ãŸã‚ˆã†ã«ã€æ–°ã—ã„ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã«ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’**åŒæœŸ**ã™ã‚‹ã¾ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯å«ã¾ã‚Œã¾ã›ã‚“ï¼š\n",
    "\n",
    "    ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãƒªã‚¹ãƒˆã§åå‰ã®å·¦å´ã«ã‚ã‚‹ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’é¸æŠã—ã¦ S3 ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’**é¸æŠ (Select)** ã—ã€ä¸Šã«ã‚ã‚‹**åŒæœŸ (Sync)** ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦åŒæœŸã‚’é–‹å§‹ã—ã¾ã™ã€‚\n",
    "\n",
    "    *Status* ãŒæ•°ç§’é–“ `Syncing` ã«å¤‰ã‚ã£ãŸå¾Œã€`Available` ã«æˆ»ã‚Šã¾ã™\n",
    "\n",
    "![](images/bedrock-kbs/04a-kb-data-source-after-sync.png \"åŒæœŸã‚’å®Ÿè¡Œã—ãŸå¾Œã® KB 'data source' ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã€ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãŒé¸æŠã•ã‚Œã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒ 'available' ã¨è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹\")\n",
    "</md>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŒæœŸãŒå®Œäº†ã™ã‚‹ã¨ã€ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã¯ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚\n",
    "\n",
    "ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€æœŸå¾…é€šã‚Šã« 20 å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒ `Added` ã•ã‚ŒãŸã‹ã©ã†ã‹ã‚’ç¢ºèªã§ãã¾ã™ï¼š\n",
    "\n",
    "<img src=\"images/bedrock-kbs/04b-kb-data-sync-details.png\" width=\"600\" alt=\"åŒæœŸãŒæ­£å¸¸ã«å®Œäº†ã—ã€20 å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ¤œå‡ºã•ã‚Œã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¿½åŠ ã•ã‚Œã€0 å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤±æ•—ã—ãŸã“ã¨ã‚’ç¤ºã™ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è©³ç´°ç”»é¢\"/>\n",
    "</md>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ\n",
    "\n",
    "å¤§è¦æ¨¡ãªè©•ä¾¡ã«ã¤ã„ã¦è­°è«–ã™ã‚‹å‰ã«ã€ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãŒæ­£ã—ãæ©Ÿèƒ½ã—ã¦ã„ã‚‹ã‹ç¢ºèªã™ã‚‹ãŸã‚ã«ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¾ã—ã‚‡ã†ã€‚ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®è©³ç´°ãƒšãƒ¼ã‚¸ã«æˆ»ã‚Šã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¾‹ãˆã°ã€ä»¥ä¸‹ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã§ã¯ã€ãƒšãƒ¼ã‚¸ä¸Šéƒ¨ã® *Knowledge Base overview* ãƒ‘ãƒãƒ«ã«ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹IDãŒ `Z746ERZP5X` ã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ï¼ˆã”è‡ªèº«ã® *Knowledge Base ID* ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰ã€‚\n",
    "\n",
    "![](images/bedrock-kbs/04c-kb-main-page.png \"ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ\")\n",
    "\n",
    "ğŸ‘‰ ä»¥ä¸‹ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®å›ºæœ‰IDã«**ç½®ãæ›ãˆ**ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ç¶šè¡Œã—ã¦ãã ã•ã„ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base_id = \"<ç½®ãæ›ãˆã‚‹>\"  # Something like \"Z746ERZP5X\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the ID identified, you can use the Bedrock runtime [RetrieveAndGenerate API](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent-runtime_RetrieveAndGenerate.html) to query your knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Victoria å·ã®çµŒæ¸ˆçŠ¶æ³ã¯ã©ã†ã§ã™ã‹ï¼Ÿ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RetrieveAndGenerate API ã¨ Nova Pro ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ã‚¨ãƒªã™ã‚‹\n",
    "rag_resp = bedrock_agent_runtime.retrieve_and_generate(\n",
    "    input={\"text\": query},\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            \"knowledgeBaseId\": knowledge_base_id,\n",
    "            \"modelArn\": f\"arn:aws:bedrock:us-west-2:{account_id}:inference-profile/us.amazon.nova-pro-v1:0\",\n",
    "        },\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "    },\n",
    "    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ ID ã¯ã€ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—è³ªå•ã®çµæœã‚’æ”¹å–„ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ï¼š\n",
    "    # sessionId='string'\n",
    ")\n",
    "\n",
    "print(\"Plain text response:\")\n",
    "print(\"--------------------\")\n",
    "print(rag_resp[\"output\"][\"text\"], end=\"\\n\\n\\n\")\n",
    "\n",
    "print(\"Full API output:\")\n",
    "print(\"----------------\")\n",
    "rag_resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šè¨˜ã®ã‚»ãƒ«ã§å‡ºåŠ›ã—ãŸãƒ•ãƒ«ã® API å¿œç­”ã«ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€`RetrieveAndGenerate` ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¯ä»¥ä¸‹ã‚’æä¾›ã—ã¾ã™ï¼š\n",
    "\n",
    "- æœ€çµ‚çš„ãªãƒ†ã‚­ã‚¹ãƒˆå›ç­”\n",
    "- æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰ã® `retrievedReferences`\n",
    "- ãƒ†ã‚­ã‚¹ãƒˆå›ç­”ã®ç•°ãªã‚‹éƒ¨åˆ†ã§å¼•ç”¨ã•ã‚Œã‚‹ã¹ãå‚ç…§ã‚’ç‰¹å®šã™ã‚‹ `citations`\n",
    "\n",
    "ã¾ãŸã€ä»¥ä¸‹ã«ç¤ºã™ã‚ˆã†ã«ã€API ã‚’é€šã˜ã¦**æ¤œç´¢ã®ã¿**ã‚’å®Ÿè¡Œã—ã€ç”Ÿæˆå›ç­”åˆæˆã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_resp = bedrock_agent_runtime.retrieve(\n",
    "    knowledgeBaseId=knowledge_base_id,\n",
    "    retrievalQuery={\"text\": query},\n",
    ")\n",
    "print(json.dumps(retrieve_resp[\"retrievalResults\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è©•ä¾¡ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨æŒ‡æ¨™ã®è¨­å®š\n",
    "\n",
    "### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿\n",
    "\n",
    "ã“ã®ä¾‹ã§ã¯ã€RAG ã‚·ã‚¹ãƒ†ãƒ ã«ã‚¯ã‚¨ãƒªã‚’é€ä¿¡ã—ã€çµæœã‚’ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ã€å‚ç…§å…¥å‡ºåŠ›ãƒšã‚¢ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚Langfuse ã‹ã‚‰æœ¬ç•ªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦ã¯ã€ä»¥é™ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯æ¬¡ã®åˆ—ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼š\n",
    "\n",
    "- `question`: list[str] - ã“ã‚Œã‚‰ã¯ã€RAG ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§è©•ä¾¡ã•ã‚Œã‚‹è³ªå•ã§ã™ã€‚\n",
    "\n",
    "- `contexts`: list[list[str]] - è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã« LLM ã«æ¸¡ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€‚\n",
    "\n",
    "- `answer`: list[str] - RAG ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‹ã‚‰ç”Ÿæˆã•ã‚Œã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æä¾›ã•ã‚Œã‚‹å›ç­”ã€‚\n",
    "\n",
    "- `ground_truths`: list[list[str]] - è³ªå•ã«å¯¾ã™ã‚‹çœŸå®Ÿã®å›ç­”ã€‚ãŸã ã—ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è©•ä¾¡ã§ã¯ã€ã“ã®ã‚±ãƒ¼ã‚¹ã§ã¯ Ground Truth ãƒ‡ãƒ¼ã‚¿ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„ãŸã‚ã€ã“ã‚Œã‚’ç„¡è¦–ã§ãã¾ã™ã€‚\n",
    "\n",
    "ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€[Exploding Gradients Dataset](https://huggingface.co/datasets/explodinggradients/fiqa/viewer/ragas_eval) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "fiqa_eval = load_dataset(\"explodinggradients/fiqa\", \"ragas_eval\")[\"baseline\"]\n",
    "fiqa_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAGAS æŒ‡æ¨™\n",
    "RAG ã‚·ã‚¹ãƒ†ãƒ ã®ä»¥ä¸‹ã®å´é¢ã‚’æ¸¬å®šã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®æŒ‡æ¨™ã¯ [RAGAS](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/) ã§å®šç¾©ã•ã‚Œã¦ã„ã¾ã™ï¼š\n",
    "\n",
    "- [Faithfulness (å¿ å®Ÿåº¦)](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/faithfulness/)ï¼šã“ã‚Œã¯ã€ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã®äº‹å®Ÿã®ä¸€è²«æ€§ã‚’ã€ä¸ãˆã‚‰ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã—ã¦æ¸¬å®šã—ã¾ã™ã€‚\n",
    "- [Response relevancy (å¿œç­”ã®é–¢é€£æ€§)](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/answer_relevance/)ï¼šResponse Relevancy æŒ‡æ¨™ã¯ã€å¿œç­”ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã«å¯¾ã—ã¦ã©ã‚Œã ã‘é–¢é€£æ€§ãŒã‚ã‚‹ã‹ã‚’æ¸¬å®šã—ã¾ã™ã€‚\n",
    "- [Context precision (ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®é©åˆç‡)](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/context_precision/)ï¼šã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé©åˆç‡ã¯ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å­˜åœ¨ã™ã‚‹ã™ã¹ã¦ã® Ground Truth ã®é–¢é€£ã‚¢ã‚¤ãƒ†ãƒ ãŒé«˜ã„ãƒ©ãƒ³ã‚¯ã«ãƒ©ãƒ³ã‚¯ä»˜ã‘ã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’è©•ä¾¡ã™ã‚‹æŒ‡æ¨™ã§ã™ã€‚ç†æƒ³çš„ã«ã¯ã€ã™ã¹ã¦ã®é–¢é€£ãƒãƒ£ãƒ³ã‚¯ãŒãƒˆãƒƒãƒ—ãƒ©ãƒ³ã‚¯ã«è¡¨ç¤ºã•ã‚Œã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "ã“ã‚Œã‚‰ã®æŒ‡æ¨™ã¨ãã®ä»•çµ„ã¿ã«ã¤ã„ã¦è©³ã—ãã¯ã€[RAGAS ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/)ã‚’ã”è¦§ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "from ragas.metrics import (\n",
    "    Faithfulness,\n",
    "    ResponseRelevancy,\n",
    "    LLMContextPrecisionWithoutReference,\n",
    ")\n",
    "\n",
    "# é¸æŠã—ãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹\n",
    "metrics = [\n",
    "    Faithfulness(),\n",
    "    ResponseRelevancy(),\n",
    "    LLMContextPrecisionWithoutReference(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.run_config import RunConfig\n",
    "from ragas.metrics.base import MetricWithLLM, MetricWithEmbeddings\n",
    "\n",
    "\n",
    "# RAGAS ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åˆæœŸåŒ–ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°\n",
    "def init_ragas_metrics(metrics, llm, embedding):\n",
    "    for metric in metrics:\n",
    "        if isinstance(metric, MetricWithLLM):\n",
    "            print(metric.name + \" llm\")\n",
    "            metric.llm = llm\n",
    "        if isinstance(metric, MetricWithEmbeddings):\n",
    "            print(metric.name + \" embedding\")\n",
    "            metric.embeddings = embedding\n",
    "        run_config = RunConfig()\n",
    "        metric.init(run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€é¸æŠã—ãŸ LLM ã¨åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦æŒ‡æ¨™ã‚’åˆæœŸåŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ä¾‹ã§ã¯ã€Amazon Bedrock Nova Pro ãƒ¢ãƒ‡ãƒ«ã¨ Cohere åŸ‹ã‚è¾¼ã¿è‹±èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã€`langchain-aws` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä¾¿åˆ©ãªãƒ©ãƒƒãƒ‘ãƒ¼ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockEmbeddings, ChatBedrockConverse\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "config = {\n",
    "    \"region_name\": \"us-west-2\",  # E.g. \"us-east-1\"\n",
    "    \"llm\": \"us.amazon.nova-pro-v1:0\",  # E.g Claude ãƒ¢ãƒ‡ãƒ«ãªã©ã‚‚åˆ©ç”¨å¯èƒ½ \"anthropic.claude-3-5-sonnet-20241022-v2:0\"\n",
    "    \"embeddings\": \"cohere.embed-english-v3\",  # E.g or \"amazon.titan-embed-text-v2:0\"\n",
    "    \"temperature\": 0.4,\n",
    "}\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(\n",
    "    ChatBedrockConverse(\n",
    "        region_name=config[\"region_name\"],\n",
    "        base_url=f\"https://bedrock-runtime.{config['region_name']}.amazonaws.com\",\n",
    "        model=config[\"llm\"],\n",
    "        temperature=config[\"temperature\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(\n",
    "    BedrockEmbeddings(\n",
    "        region_name=config[\"region_name\"],\n",
    "        model_id=config[\"embeddings\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "init_ragas_metrics(\n",
    "    metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embedding=evaluator_embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langfuse ã§è©•ä¾¡çµæœã‚’ãƒˆãƒ¬ãƒ¼ã‚¹ã™ã‚‹\n",
    "\n",
    "RAGAS ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡ã‚’è¡Œã†æ–¹æ³•ã¯ 2 ã¤ã‚ã‚Šã¾ã™ï¼š\n",
    "1. ã™ã¹ã¦ã®ãƒˆãƒ¬ãƒ¼ã‚¹ã«ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã‚‹ï¼šã“ã‚Œã¯ã€å„ãƒˆãƒ¬ãƒ¼ã‚¹é …ç›®ã«å¯¾ã—ã¦è©•ä¾¡ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€RAG ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¸ã®å„å‘¼ã³å‡ºã—ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ã¤ã„ã¦ã‚ˆã‚Šè‰¯ã„ã‚¢ã‚¤ãƒ‡ã‚¢ãŒå¾—ã‚‰ã‚Œã¾ã™ãŒã€ã‚³ã‚¹ãƒˆã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "2. ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ã‚¹ã‚³ã‚¢ä»˜ã‘ï¼šã“ã®æ–¹æ³•ã§ã¯ã€å®šæœŸçš„ã«ãƒˆãƒ¬ãƒ¼ã‚¹ã®ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒ«ã‚’å–å¾—ã—ã€ãã‚Œã‚‰ã«ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã‚³ã‚¹ãƒˆãŒå‰Šæ¸›ã•ã‚Œã€ã‚¢ãƒ—ãƒªã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®æ¦‚ç®—ãŒå¾—ã‚‰ã‚Œã¾ã™ãŒã€é‡è¦ãªã‚µãƒ³ãƒ—ãƒ«ã‚’è¦‹é€ƒã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "ã“ã®ä¾‹ã§ã¯ã€äº‹å‰æ§‹ç¯‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ Amazon Bedrock Knowlegebase ã‚’ä½¿ç”¨ã—ãŸ RAG ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€ä¸¡æ–¹ã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è©¦ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã™ã¹ã¦ã®ãƒˆãƒ¬ãƒ¼ã‚¹ã«ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã‚‹\n",
    "\n",
    "å˜ä¸€ã®ãƒˆãƒ¬ãƒ¼ã‚¹ã®å°ã•ãªä¾‹ã‚’å–ã‚Šä¸Šã’ã€RAGAS ã§ã©ã®ã‚ˆã†ã«ã‚¹ã‚³ã‚¢ä»˜ã‘ã§ãã‚‹ã‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ã¾ãšã€é¸æŠã—ãŸæŒ‡æ¨™ã§ãƒˆãƒ¬ãƒ¼ã‚¹ã«ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã‚‹ãŸã‚ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.dataset_schema import SingleTurnSample\n",
    "\n",
    "\n",
    "async def score_with_ragas(query, chunks, answer, metrics):\n",
    "    scores = {}\n",
    "    for metric in metrics:\n",
    "        sample = SingleTurnSample(\n",
    "            user_input=query,\n",
    "            retrieved_contexts=chunks,\n",
    "            response=answer,\n",
    "        )\n",
    "        print(f\"{metric.name} è¨ˆç®—ä¸­...\")\n",
    "        scores[metric.name] = await metric.single_turn_ascore(sample)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé …ç›®ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°\n",
    "\n",
    "å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã¾ã™ã€‚ä»¥ä¸‹ã§ã¯ã€ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œã™ã‚‹ãƒ€ãƒŸãƒ¼ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èª¬æ˜ã—ã¾ã™ï¼š\n",
    "\n",
    "- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰è³ªå•ã‚’å–å¾—ã™ã‚‹\n",
    "- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ä½¿ç”¨ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¾ãŸã¯ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‹ã‚‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹\n",
    "- è³ªå•ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ LLM ã«æ¸¡ã—ã¦å›ç­”ã‚’ç”Ÿæˆã™ã‚‹\n",
    "\n",
    "ã“ã®å ´åˆã€Langfuse Python [ä½ãƒ¬ãƒ™ãƒ« SDK](https://langfuse.com/docs/sdk/python/low-level-sdk) ã‚’ä½¿ç”¨ã—ã¦ã€ã‚ˆã‚Šè©³ç´°ãªåˆ¶å¾¡ã§ãƒˆãƒ¬ãƒ¼ã‚¹ã«ãƒ­ã‚°ã‚’è¨˜éŒ²ã™ã‚‹ä½¿ç”¨æ–¹æ³•ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€å¾Œç¶šã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ [ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿](https://langfuse.com/docs/sdk/python/decorators) ã‚’ä½¿ç”¨ã—ãŸä¾‹ã‚’è¦‹ãŸã‚Šã€[langfuse ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://langfuse.com/docs/sdk/overview)ã§è©³ç´°ã‚’èª­ã‚€ã“ã¨ã‚‚ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è³ªå•ã‚’å—ã‘ãŸã‚‰æ–°ã—ã„ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’é–‹å§‹\n",
    "row = fiqa_eval[0]\n",
    "question = row[\"question\"]\n",
    "trace = langfuse.trace(name=\"rag-fiqa\")\n",
    "\n",
    "# é–¢é€£ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—\n",
    "# chunks = get_similar_chunks(question)\n",
    "contexts = row[\"contexts\"]\n",
    "# ã‚¹ãƒ‘ãƒ³ã«æ¸¡ã™\n",
    "trace.span(\n",
    "    name=\"retrieval\", input={\"question\": question}, output={\"contexts\": contexts}\n",
    ")\n",
    "\n",
    "# LLM ã‚’ä½¿ã£ã¦ãƒãƒ£ãƒ³ã‚¯ã«åŸºã¥ã„ãŸå›ç­”ã‚’ç”Ÿæˆ\n",
    "# answer = get_response_from_llm(question, chunks)\n",
    "answer = row[\"answer\"]\n",
    "trace.generation(\n",
    "    name=\"generation\",\n",
    "    input={\"question\": question, \"contexts\": contexts},\n",
    "    output={\"answer\": answer},\n",
    ")\n",
    "\n",
    "# è³ªå•ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€å›ç­”ã®ã‚¿ãƒ—ãƒ«ã®ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—\n",
    "ragas_scores = await score_with_ragas(question, contexts, answer, metrics)\n",
    "ragas_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Langfuse ã§ãƒˆãƒ¬ãƒ¼ã‚¹ã•ã‚Œã¦ã„ã¾ã™ãŒã€ã‚¹ã‚³ã‚¢ã¯ã¾ã ã¤ã„ã¦ã„ã¾ã›ã‚“ã€‚Langfuse UI ã§ç¢ºèªã§ãã¾ã™:\\n{os.environ['LANGFUSE_HOST']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»¥ä¸‹ã®ã‚ˆã†ã«å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã«ã‚¹ã‚³ã‚¢ã‚’æ·»ä»˜ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¹ã‚³ã‚¢ã‚’é€ä¿¡\n",
    "for m in metrics:\n",
    "    trace.score(name=m.name, value=ragas_scores[m.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the score is attached\n",
    "\n",
    "![](images/bedrock-kbs/04e-langfuse-single-eval-trace-score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°\n",
    "æœ€åˆã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ Amazon Bedrock Knowledge Bases ã‚’è¨­å®šæ¸ˆã¿ãªã®ã§ã€ä»Šåº¦ã¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ãã®çµæœã®å“è³ªã‚’**è©•ä¾¡**ã—ã€é«˜å“è³ªã‹ã¤ä½ã‚³ã‚¹ãƒˆã®æ§‹æˆã«**æœ€é©åŒ–**ã™ã‚‹ãŸã‚ã®æ‰‹åŠ©ã‘ã‚’ã—ã¾ã™ã€‚\n",
    "\n",
    "ã¾ãšã€è³ªå•ã€å‚ç…§å›ç­”ã€ãŠã‚ˆã³ãã®ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã™ï¼ˆã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™æ–¹æ³•ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€[ã“ã® GitHub](https://github.com/aws-samples/llm-evaluation-methodology/blob/main/datasets/Prepare-SQuAD.ipynb) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ï¼‰ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_json(\"datasets/qa.manifest.jsonl\", lines=True)\n",
    "dataset_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™ï¼š\n",
    "\n",
    "- (`doc`) ã“ã®ã‚µãƒ³ãƒ—ãƒ«ã«å¯¾ã™ã‚‹ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å…¨æ–‡\n",
    "- (`doc_id`) ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸€æ„ã®è­˜åˆ¥å­\n",
    "- (`question`) ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå°‹ã­ã‚‹è³ªå•\n",
    "- (`question_id`) è³ªå•ã®ä¸€æ„ã®è­˜åˆ¥å­\n",
    "- (`answers`) ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã‚ˆã£ã¦ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹ï¼ˆè¤‡æ•°ã®å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰å‚ç…§ã€Œæ­£è§£ã€ã®ãƒªã‚¹ãƒˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[RAGAS ã® API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹](https://docs.ragas.io/en/latest/references/evaluation.html)ã«ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€RAGAS è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã«ã¯é€šå¸¸ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™ï¼š\n",
    "\n",
    "- å°‹ã­ã‚‰ã‚ŒãŸ `question`\n",
    "- ã‚·ã‚¹ãƒ†ãƒ ãŒç”Ÿæˆã—ãŸ `answer`\n",
    "- ç­”ãˆã®æ ¹æ‹ ã¨ãªã£ãŸå®Ÿéš›ã®ãƒ†ã‚­ã‚¹ãƒˆ `contexts`ï¼ˆã¤ã¾ã‚Šã€æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã«ã‚ˆã£ã¦å–å¾—ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆã®ã‚¹ãƒ‹ãƒšãƒƒãƒˆï¼‰\n",
    "- `ground_truth` ã®ç­”ãˆ\n",
    "\n",
    "ã“ã“ã§ã¯ã€`@observe()` ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã€Langfuse Python SDK ã§ [Langfuse ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°](https://langfuse.com/docs/tracing) ã‚’ RAG ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ±åˆã—ã¾ã™ã€‚\n",
    "\n",
    "ä»¥ä¸‹ã«ç¤ºã™ã‚ˆã†ã«ã€Amazon Bedrock KB ã®å–å¾—ãŠã‚ˆã³ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ä¾‹ã®è³ªå•ã‚’å®Ÿè¡Œã—ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—ã™ã‚‹æº–å‚™ãŒã§ããŸå‚ç…§ã‚’æŠ½å‡ºã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import observe, langfuse_context\n",
    "\n",
    "\n",
    "@observe(name=\"Knowledge Base Retrieve and Generate\")\n",
    "def retrieve_and_generate(\n",
    "    question: str,\n",
    "    kb_id: str,\n",
    "    generate_model_arn: str = f\"arn:aws:bedrock:us-west-2:{account_id}:inference-profile/us.amazon.nova-pro-v1:0\",\n",
    "    **kwargs,\n",
    "):\n",
    "    rag_resp = bedrock_agent_runtime.retrieve_and_generate(\n",
    "        input={\"text\": question},\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            \"knowledgeBaseConfiguration\": {\n",
    "                \"knowledgeBaseId\": kb_id,\n",
    "                \"modelArn\": generate_model_arn,\n",
    "            },\n",
    "            \"type\": \"KNOWLEDGE_BASE\",\n",
    "        },\n",
    "    )\n",
    "    answer = rag_resp[\"output\"][\"text\"]\n",
    "\n",
    "    # ãƒã‚¹ãƒˆã•ã‚ŒãŸå¼•ç”¨æ–‡çŒ®ã‹ã‚‰ãƒ•ãƒ©ãƒƒãƒˆãªå¼•ç”¨æ–‡çŒ®ãƒªã‚¹ãƒˆã‚’å–å¾— -> retrievedReferences:\n",
    "    all_refs = [\n",
    "        r for cite in rag_resp[\"citations\"] for r in cite[\"retrievedReferences\"]\n",
    "    ]\n",
    "    contexts = [r[\"content\"][\"text\"] for r in all_refs]\n",
    "    ref_s3uris = [r[\"location\"][\"s3Location\"][\"uri\"] for r in all_refs]\n",
    "    # ãƒãƒƒãƒ”ãƒ³ã‚° e.g. 's3://.../doc_id.txt' -> 'doc_id':\n",
    "    ref_ids = [uri.rpartition(\"/\")[2].rpartition(\".\")[0] for uri in ref_s3uris]\n",
    "\n",
    "    # ãƒˆãƒ¬ãƒ¼ã‚¹ã™ã‚‹è¿½åŠ ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜éŒ²\n",
    "    langfuse_context.update_current_observation(\n",
    "        input={\"question\": question, \"contexts\": contexts},\n",
    "        output=answer,\n",
    "        model=\"us.amazon.nova-pro-v1:0\",\n",
    "        session_id=\"kb-rag-session\",\n",
    "        tags=[\"dev\"],\n",
    "        metadata=kwargs,\n",
    "    )\n",
    "\n",
    "    # ç‹¬ç«‹ã—ãŸã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã®ãŸã‚ã«ãƒˆãƒ¬ãƒ¼ã‚¹ ID ã‚’å–å¾—\n",
    "    trace_id = langfuse_context.get_current_trace_id()\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"retrieved_doc_ids\": ref_ids,\n",
    "        \"retrieved_doc_texts\": contexts,\n",
    "        \"trace_id\": trace_id,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒæ¥ãŸã‚‰ RAG ã‚’å®Ÿè¡Œã—ã€çµæœã‚’ã™ãã«ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import observe, langfuse_context\n",
    "from asyncio import run\n",
    "\n",
    "\n",
    "@observe(name=\"Knowledge Base Pipeline\")\n",
    "def rag_pipeline(\n",
    "    question,\n",
    "    user_id: Optional[str] = None,\n",
    "    session_id: Optional[str] = None,\n",
    "    kb_id: Optional[str] = None,\n",
    "    metrics: Optional[Any] = None,\n",
    "):\n",
    "\n",
    "    generated_answer = retrieve_and_generate(\n",
    "        question=question,\n",
    "        kb_id=kb_id,\n",
    "        kwargs={\"database\": \"Bedrock Knowledge Base\", \"kb_id\": kb_id},\n",
    "    )\n",
    "    contexts = generated_answer[\"retrieved_doc_texts\"]\n",
    "    answer = generated_answer[\"answer\"]\n",
    "    trace_id = generated_answer[\"trace_id\"]\n",
    "\n",
    "    score = run(score_with_ragas(question, contexts, answer=answer, metrics=metrics))\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=user_id,\n",
    "        session_id=session_id,\n",
    "        tags=[\"dev\"],\n",
    "    )\n",
    "    for s in score:\n",
    "        langfuse.score(name=s, value=score[s], trace_id=trace_id)\n",
    "    return generated_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_pipeline(dataset_df.iloc[0][\"question\"], kb_id=knowledge_base_id, metrics=metrics)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã‚‹\n",
    "\n",
    "ã™ã¹ã¦ã®ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒˆãƒ¬ãƒ¼ã‚¹ã«ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã‚‹ã“ã¨ã¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¼ã‚„ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã«ã‚ˆã£ã¦ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã€ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ãã®å ´åˆã¯ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•ã‚’æ¡ç”¨ã™ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†ã€‚ãƒãƒƒãƒå‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã‚¿ã‚¤ãƒ ã‚¹ãƒ©ã‚¤ã‚¹ã¨ã€ãã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ©ã‚¤ã‚¹ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ãƒˆãƒ¬ãƒ¼ã‚¹ã®æ•°ã‚’æ±ºå®šã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã€`ragas.evaluate` ã‚’å‘¼ã³å‡ºã—ã¦çµæœã‚’åˆ†æã—ã¾ã™ã€‚\n",
    "\n",
    "ã“ã‚Œã‚’å®šæœŸçš„ã«å®Ÿè¡Œã—ã¦ã€ã‚¿ã‚¤ãƒ ã‚¹ãƒ©ã‚¤ã‚¹é–“ã§ã‚¹ã‚³ã‚¢ãŒã©ã®ã‚ˆã†ã«å¤‰åŒ–ã—ã¦ã„ã‚‹ã‹ã‚’è¿½è·¡ã—ã€ä¸ä¸€è‡´ãŒãªã„ã‹ã‚’ç¢ºèªã§ãã¾ã™ã€‚\n",
    "\n",
    "å…ˆã»ã© `retrieve_and_generate()` é–¢æ•°ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸæ—¢å­˜ã®çµæœã‚’è©•ä¾¡ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã¾ãšã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æœ€åˆã® 10 å•ã«å¯¾ã—ã¦ RAG ã‚’å®Ÿè¡Œã—ã€10 å€‹ã®ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_generated_outputs = [\n",
    "    retrieve_and_generate(\n",
    "        question=rec.question,\n",
    "        kb_id=knowledge_base_id,\n",
    "        kwargs={\"database\": \"Bedrock Knowledge Base\", \"kb_id\": knowledge_base_id},\n",
    "    )\n",
    "    for _, rec in dataset_df.head(10).iterrows()\n",
    "]\n",
    "rag_generated_outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langfuse ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸçµæœã¯ã€ä»¥ä¸‹ã®ä¾¿åˆ©ãªé–¢æ•°ã‚’ä½¿ã£ã¦å¿…è¦ã«å¿œã˜ã¦å–ã‚Šå‡ºã™ã“ã¨ãŒã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.api.resources.commons.types.trace_with_details import TraceWithDetails\n",
    "\n",
    "def get_traces(\n",
    "    limit: int = 5,\n",
    "    name: Optional[str] = None,\n",
    "    user_id: Optional[str] = None,\n",
    "    session_id: Optional[str] = None,\n",
    "    from_timestamp: Optional[str] = None,\n",
    "    to_timestamp: Optional[str] = None,\n",
    ") -> List[TraceWithDetails]:\n",
    "    \"\"\"ä¸ãˆã‚‰ã‚ŒãŸãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ãƒãƒƒãƒã™ã‚‹ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’Langfuseã«ã‚¯ã‚¨ãƒªã™ã‚‹ã€‚\n",
    "    è©³ç´°ã¯ https://langfuse.com/docs/query-traces ã‚’ç¢ºèªã€‚\"\"\"\n",
    "\n",
    "    all_data = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        response = langfuse.fetch_traces(\n",
    "            page=page,\n",
    "            name=name,\n",
    "            user_id=user_id,\n",
    "            session_id=session_id,\n",
    "            from_timestamp=from_timestamp,\n",
    "            to_timestamp=to_timestamp,\n",
    "        )\n",
    "        if not response.data:\n",
    "            break\n",
    "        page += 1\n",
    "        all_data.extend(response.data)\n",
    "        if len(all_data) > limit:\n",
    "            break\n",
    "\n",
    "    return all_data[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "NUM_TRACES_TO_SAMPLE = 3\n",
    "traces = get_traces(name=\"Knowledge Base Retrieve and Generate\", limit=10)\n",
    "if len(traces) > NUM_TRACES_TO_SAMPLE:\n",
    "    traces_sample = sample(traces, NUM_TRACES_TO_SAMPLE)\n",
    "else:\n",
    "    traces_sample = traces\n",
    "\n",
    "print(f\"{len(traces)} ä»¶ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã•ã‚ŒãŸãƒˆãƒ¬ãƒ¼ã‚¹ã‹ã‚‰ {len(traces_sample)} ä»¶ã®ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¾ã—ãŸã€‚\")\n",
    "for trace in traces_sample:\n",
    "    print(f\"Trace ID: {trace.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€ãƒãƒƒãƒã‚’ä½œæˆã—ã¦ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã¾ã—ã‚‡ã†ã€‚RAGAS ã¯ã€huggingface ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã€è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ã“ã‚Œã‚’ç‹¬è‡ªã®ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã§å®Ÿè¡Œã™ã‚‹å ´åˆã¯ã€é©åˆ‡ãªã‚­ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ã‚¹ã‹ã‚‰è³ªå•ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€ãŠã‚ˆã³å›ç­”ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚¹ã‚³ã‚¢ä»˜ã‘\n",
    "evaluation_batch = {\n",
    "    \"question\": [],\n",
    "    \"contexts\": [],\n",
    "    \"answer\": [],\n",
    "    \"trace_id\": [],\n",
    "}\n",
    "\n",
    "for sample in traces_sample:\n",
    "    evaluation_batch[\"question\"].append(sample.input[\"question\"])\n",
    "    evaluation_batch[\"contexts\"].append(sample.input[\"contexts\"])\n",
    "    evaluation_batch[\"answer\"].append(sample.output)\n",
    "    evaluation_batch[\"trace_id\"].append(sample.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAGAS evaluate é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ï¼ˆå˜ä¸€ã‚¿ãƒ¼ãƒ³ã®ã‚„ã‚Šå–ã‚Šã§ã¯ãªãï¼‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã«ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã¾ã™ã€‚è©³ç´°ã«ã¤ã„ã¦ã¯ã€[RAGAS evaluate](https://docs.ragas.io/en/latest/references/evaluate/) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGAS evaluate ã‚’å®Ÿè¡Œ\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import Faithfulness, ResponseRelevancy\n",
    "\n",
    "ds = Dataset.from_dict(evaluation_batch)\n",
    "evals_results = evaluate(\n",
    "    ds,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    metrics=[Faithfulness(), ResponseRelevancy()],\n",
    ")\n",
    "evals_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã‚Œã§å®Œäº†ã§ã™ï¼ä¸€å®šæœŸé–“ã«ã‚ãŸã‚‹ã‚¹ã‚³ã‚¢ã‚’ç¢ºèªã§ãã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã§çµæœã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã—ã¦ã€ã‚¹ã‚³ã‚¢ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = evals_results.to_pandas()\n",
    "\n",
    "# çµæœã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã« Langfuse trace_id ã‚’è¿½åŠ \n",
    "df[\"trace_id\"] = ds[\"trace_id\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚¹ã‚³ã‚¢ã‚’ Langfuse ã«ãƒ—ãƒƒã‚·ãƒ¥ãƒãƒƒã‚¯ã—ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã«æ·»ä»˜ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df.iterrows():\n",
    "    for metric_name in [\"faithfulness\", \"answer_relevancy\"]:\n",
    "        langfuse.score(\n",
    "            name=metric_name, value=row[metric_name], trace_id=row[\"trace_id\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langfuse ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«æˆ»ã£ã¦ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã§æ›´æ–°ã•ã‚ŒãŸã‚¹ã‚³ã‚¢ã‚’ç¢ºèªã§ãã¾ã™ã€‚\n",
    "\n",
    "![](images/bedrock-kbs/score-with-sampling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼\n",
    "ãƒ©ãƒœ 2 ã‚’ç„¡äº‹çµ‚äº†ã—ã¾ã—ãŸã€‚\n",
    "\n",
    "AWS ã‚¤ãƒ™ãƒ³ãƒˆã«å‚åŠ ã—ã¦ã„ã‚‹å ´åˆã¯ã€æ¬¡ã®ãƒ©ãƒœã«é€²ã‚€å‰ã«ã€ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ã‚¹ã‚¿ã‚¸ã‚ªã«æˆ»ã£ã¦è¿½åŠ ã®æŒ‡ç¤ºã‚’ç¢ºèªãã ã•ã„ã€‚æ¬¡ã®ãƒ©ãƒœã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡ã¨ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ã«ã¤ã„ã¦å­¦ç¿’ã—ã¾ã™ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
